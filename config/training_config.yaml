# Model parameters
model_name: "google/gemma-3-1b-it"
lora_r: 16
lora_alpha: 32
lora_target_modules: "all-linear"  # Or specify a list of modules

# Data parameters
# train_data_path: "data/gsm8k/train.jsonl" # removing this as we will pass the model to the function
# eval_data_path: "data/gsm8k/test.jsonl"
max_prompt_length: 512 # making sure it matches
max_completion_length: 512 # making sure it matches
# Training parameters
learning_rate: 5.0e-6
batch_size: 2
gradient_accumulation_steps: 1
num_epochs: 1
max_steps: 250
save_steps: 250
warmup_ratio: 0.1
weight_decay: 0.1
report_to: "none"
output_dir: "output"  # Where to save the model weights
logging_steps: 1

#GRPO Parameters
num_generations: 2
